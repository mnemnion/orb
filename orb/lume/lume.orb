* Lume


The old toolchain had a codex.

This one is going to have a Lume.  Which sounds like loom, and looks like
light, and that will do.


** Premise

  Orb being a hypertextual medium, we must /resolve/ references between
documents.  Normal operation works on a project at a time, but this was
Proctrustean: sometimes too large for the job, and sometimes too small.

The Lume, which will undergo several metamorphoses on its path to the final
boss form, is a general-purpose document resolver and skein wrangler.  We give
it essentially a URL, it gives us back a promise to provide that data, in the
form of a coroutinized callback.

That's one of the tricky parts.  Bridge programs run on an event loop, and we
have a threadpool for doing filesystem I/O, so this does come with notional
speed benefits, even for loading files from store.

But for retrieving remote work, we would absolutely crawl if we had to wait
for each network request to resolve before launching another one.  There's no
alternative but to finally internalise the paradigm which luvit uses for doing
async work in a single-threaded callback + coroutine framework.

I'll probably end up writing blocking versions of most of the basic
operations, because it's simpler, and because it's our only hope of having
colorless functions: ones which don't have to know, at call-time, that they
must be inside a coroutine and handled accordingly.


*** Vocabulary

#Todo URLify all the definitions in this section

We refer to the project root as the =codex=, but we simply must break the
requirement that it have "codex normal form".  Bridge projects will continue
to follow the form, which remains useful, but we require ways to override it,
and ways to continue operation, in some circumstances, without the familiar
directories.

A =deck= is what we will call each meta-directory within a Codex.  Meta in the
sense that each source, knit, and weave directory, is /basically/ a single
entity with different faces.  We do have to decide under what circumstances
this correspondence can be broken, and how we inform the Lume that this is
happening, so that it doesn't delete artifacts that appear to have no further
basis in the source.

A =manifest= is our specification document.  Any codex exists in a profusion
of different versions from a variety of sources of truth, and if we mean a
specific one, we need to tell the Lume which one we mean.  Manifests are
initially loaded from specific files, located in the base of the Deck which
they influence, but a Deck's manifest is an in-memory data structure which may
be further modified by information contained in Docs.

That is itself a bit bewildering but there's a simple remedy: each Codex,
Deck, and Doc, has a single associated Manifest, and if that Manifest has any
modifications relative to its parent, it is turned into an /instance/ which
has the parent as a metatable.  This is the cheaper and more eloquent way to
do it: the cleanest way is to make each and every Manifest an instance with
a metatable structure which leads back to the root.  We'll decide later.

A =skein= is a meta-Doc in the way in which a Deck is a meta-directory; it
handles all the permutations of a given document, and is responsible for
handling messages to do operations, and returning messages and closures which
manifest hyper-linking, transclusion, and this sort of thing.

Each =skein= has a reference to its Lume, and might end up carrying a
reference to its Deck as well.  Skeins don't do much with Decks per se,
however, and we can derive it from the Skein's base path, so perhaps not.

The big piece I'm missing is how to handle queuing of asynchronous operations,
such that the Lume can tell, during each pass through libuv, what operations
are ready to be taken to the next level.  Once I've really grasped that, the
rest is, not straightforward, but surely tractable.


**** Fields


Because of the centrality of the Codex to operation of a Lume, its references
are "exploded" in the Lume.  That is, the =orb=, =src= and =doc= directories
are instance fields on the Lume itself, not (primarily) on the =codex= object.

It's awkward to have to imperatively command the Lume to retrieve some data,
so indexing the @namegoeshere will return a closure which we can call
repeatedly until it has something to give us.  I /think/ that's how this
should work; this is my first time writing a beast of this nature, and I
should expect to do a shoddy job of it the first time around.

Actually, I'm thinking that we create a /coroutine/ on the spot, and when the
inner callback returns a value, this is placed on a work queue to be further
processed by the Lume idler.  Or something like that; I'm going to need to do
some flowcharting to really get this thing right.

There's some small advantage to making this perfectly consistent, but it's
less efficient, so I believe we'll just have this index return a Skein if it
happens to already have one, and the promise of a Skein if it does not.

Using an =__index= function lets us be smart about not caring if this index is
a string, a Path, File, a Skein (which sounds like a no-op but bear with me),
or something exotic we aren't using yet, like an URL node.  Canonicalizing all
these possibilities is often, but not always, straightforward, and in any
case we benefit from having a single place where it happens.

Lumes also have to handle inter-skein communication.  Our first case, and the
one we can build the rest on, is a transclusion: here the Lume encounters an
operation within a Skein which cannot be completed without information in
another Doc, and it doesn't want to know at the time whether or not that
information is already present.  It may buy us time, at the expense of
complexity, to resolve the reference on the spot if we're already able, but
this is an optimization.

What the knitter (for the sake of argument) returns is a closure, along with
the information it has on hand as to how to provide the additional parameters
needed to call the closure.  So if we've encountered a ``#transclude`` block,
we'll get back a closure which inserts the transcluded text into the Scroll,
at the current offset, and the ``@name`` of the transclude block, used to
retrieve the associated Doc and =:select= the necessary Twig.

There's no reason for this to ever live on the Skein, when we can retrieve the
Lume from the Skein and place it there immediately.


*** Stop. Hammock Time.

  So there are a number of unanswered questions here, and I do need to obtain
some clarity on them before I can start to sketch out the implementation.

A Lume is opened any time we have a Doc, with the minimum-viable amount of
support infrastructure surrounding it.

This sort of needs to be built inside out.  =bridge= has to be able to handle
an invocation such as =br example.orb=, which should knit =example.orb= and
execute it.  This will create a Lume, yes, and it shouldn't have to look at
anything that isn't directly implicated in loading the sorcery.

Expanding outward, the paradigm case is actually =br orb serve= typed from the
root directory of a Codex.  This should case the entire Codex into a Lume,
generate a bundle and all artifacts, then set up a file watcher which conducts
changes.  At some point this develops the ability to talk to =helm=, an editor,
and other such constructions.

The whole goal of bridge is to tighten the OODA loop between editing text and
seeing the changes to the system, after all.

A fully-operational Lume will need to be retrieving changes from a remote
code repository and walking the user through an interaction about whether to
update Manifests to point to new revisions, should allow changes to a Doc's
source through inline editing of a woven HTML view, wants to intercept error
messages from runtimes and sent a message to text editors to display the
offending piece of (orb!) source code, and so on, and so forth.

The challenge is to build the Lume so that it can be repeatedly extended until
it reaches this final boss form.  The Lume isn't a dumpster, but it does have
a complex remit, and is called upon in the moment to be both more and less
than the Codex which it replaces.

The main hangup is two related things: how to handle an asynchronous operation,
and where/how to store things which are in transit.

Let me break this down.  Lume has three kinds of data: something which can
resolve a variety of messages into the associated data/Skein, something which
marshals in-process tasks while they are in flight, and various slots which
hold useful data: two examples of this are the Directory for the root Codex,
and a table with =git= informaiton for it.

I'm starting to think the process management / queue / event worker thingie is
its own module, and that the Lume is just the web of resolutions and the
directory for all cross-skein data transfer and 'global state'.


**** First Steps

  The initial goal is to reach feature parity with the existing Codex
implementation.

The constructor is relatively straightforward, main difference this time is
that we don't want to silently break later if the root directory isn't in
codex normal form.

The workflow for the new runner is approximately this:

-  Case the Orb directory and generate Skeins for each =.orb= file we find.

-  Launch a coroutine, per file, which triggers the 'callback style' of
   opening, while counting the number of operations we have in flight.

   Each of these coroutines, when it resumes, will decrement the counter.

  -  After queuing the =sk:load()= into the threadpool, set up an idler which
     simply checks to see if the count is back at zero, and exits if it isn't.

     When the documents are all loaded, iterate them and run them through the
     spin/knit/weave/compile/cycle.

     I think this can all be written into the initial coroutine, which is
     simply resumed.  All of these operations are blocking, there's no way to
     make them faster without experimenting with threads, and I doubt (no way
     to know without profiling) that any CPU operations will be a meaningful
     target for optimization.

  -  The last step is to use the same callback pattern to write out any new
     files.  The database persistence needs to be a transaction anyway, and I
     don't think we'll be helping ourselves by trying to put it into libuv,
     we'll just let SQLite take care of it.  But we can absolutely write
     files without having to wait around while the system does what it does.

This will handle everything we currently do with Orb, and give me a framework
for reasoning about how to do the more complex tasks ahead.


** Lume


**** imports

#!lua
local git_info = require "orb:util/gitinfo"
local Dir  = require "fs:directory"
local File = require "fs:file"
local Path = require "fs:path"
local git_info = require "orb:util/gitinfo"
#/lua

#!lua
local Lume = {}
Lume.__index = Lume
#/lua

The workflow we envision will have one active Lume per instance, but that's
not a fact of nature, so we'll key the unique off the file path.

Doing this right requires resolving symlinks, making relative file paths
absolute, and probably the best option, retrieving the directory inode.  But
we might just do it wrong at first.

#!lua
local _Lumes = setmetatable({}, { __mode = "kv" })
#/lua


****  _findSubdirs(lume, dir)

  Called by the constructor to find the directories for knitted and woven
artifacts, should they happen to exist.

#!lua
local function _buildLume(lume, dir)
   local isCo = false
   local orbDir, srcDir, libDir = nil, nil, nil
   local docDir, docMdDir, docDotDir, docSvgDir = nil, nil, nil, nil
   lume.root = dir
   local subdirs = dir:getsubdirs()

   for i, sub in ipairs(subdirs) do
      local name = sub:basename()
      if name == "orb" then
         s:verb("orb: " .. tostring(sub))
         orbDir = sub
         lume.orb = sub
         -- dumb hack because I mutated this parameter >.<
         lume.orb_base = sub
      elseif name == "src" then
         s:verb("src: " .. tostring(sub))
         srcDir = Dir(sub)
         lume.src = sub
      elseif name == "doc" then
         s:verb("doc: " .. tostring(sub))
         docDir = sub
         lume.doc = sub
         local subsubdirs = docDir:getsubdirs()
         for j, subsub in ipairs(subsubdirs) do
            local subname = subsub:basename()
            if subname == "md" then
               s:verb("doc/md: " .. tostring(subsub))
               docMdDir = subsub
               lume.docMd = subsub
            elseif subname == "dot" then
               s:verb("doc/dot: " .. tostring(subsub))
               docDotDir = subsub
               lume.docDot = subsub
            elseif subname == "svg" then
               s:verb("doc/svg: " .. tostring(subsub))
               docSvgDir = subsub
               lume.docSvg = subsub
            end
         end
      end
   end

   return lume
end
#/lua


***  Lume(dir)

Creates a Lume, rooted in the provided Directory, which may be a string or a
Dir.

#!lua
local function new(dir)
   if type(dir) == "string" then
      dir = Dir(dir)
   end
   -- #todo this should use a unique property of the directory, which the
   -- inode is and the path string is not.
   if __Lumes[dir] then
      return __Lumes[dir]
   end
   local lume = setmetatable({}, Lume)
   lume = _findSubdirs(dir, lume)
   lume.project = dir.path[#dir.path] -- hmmm?
   lume.git_info = git_info(tostring(dir))
   lume.docs  = {}
   lume.files = {}
   lume.srcs  = {}
   lume.docMds = {}
   lume.docSvgs = {}
   lume.docDots = {}
   -- lume.docHtmls = {} #todo

   lume.bytecodes = {}
   return lume
end
#/lua